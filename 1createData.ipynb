{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "3898892d7e34557bb8499aff9aa0ccd3bf7bab375649613f01d0952879e4c360"
   }
  },
  "interpreter": {
   "hash": "3898892d7e34557bb8499aff9aa0ccd3bf7bab375649613f01d0952879e4c360"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Users\\thilo\\OneDrive\\Dokumente\\Universit채tLeipzig\\DataScience2\\BigData\\tokenizer.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.iloc[b_brand.index.asi8[x]:b_brand.index.asi8[x]+len(bList)]['Attribut'] = \"I-Brand\"\n",
      "     satzId      Wort       Attribut\n",
      "0         0     Front              O\n",
      "1         0  controls              O\n",
      "2         0    Easily  B-Modelnumber\n",
      "3         0   operate              O\n",
      "4         0      your              O\n",
      "..      ...       ...            ...\n",
      "101       0       and              O\n",
      "102       0    remove              O\n",
      "103       0       for              O\n",
      "104       0      easy              O\n",
      "105       0  cleaning              O\n",
      "\n",
      "[106 rows x 3 columns]\n",
      "    satzId   Wort Attribut\n",
      "17       0  Sensi  B-Brand\n",
      "    satzId  Wort Attribut\n",
      "18       0     -  I-Brand\n",
      "19       0  Temp  I-Brand\n",
      "    satzId        Wort Attribut\n",
      "20       0  Technology  E-Brand\n",
      "   satzId    Wort       Attribut\n",
      "2       0  Easily  B-Modelnumber\n",
      "[range(0, 2000, 8), range(1, 2000, 8), range(2, 2000, 8), range(3, 2000, 8), range(4, 2000, 8), range(5, 2000, 8), range(6, 2000, 8), range(7, 2000, 8)]\n"
     ]
    }
   ],
   "source": [
    "import tokenizer as tok\n",
    "import pandas as pd\n",
    "from multiprocessing import Process, Queue\n",
    "\n",
    "def f(queue, ecsv, rows):\n",
    "    df = pd.DataFrame()\n",
    "    for index, row in ecsv.iterrows():\n",
    "        if index not in rows:\n",
    "            continue\n",
    "        df = df.append(tok.tokenizer(index, str(row['name']) + ' ' + str(row['productdescription']), str(row['brand']), str(row['modelnumber'])))\n",
    "        # if index % 1000 == 0:\n",
    "        #     print('Verarbeitete Produkte:', index)\n",
    "        #     df.to_csv('Daten/trainingData.csv', index = False)\n",
    "    queue.put(df)\n",
    "\n",
    "ecsv = pd.read_csv('Daten/KoepckeEigen/electronicFixed.csv',escapechar=\"\\\\\",sep=\",\",error_bad_lines=False,warn_bad_lines=False)\n",
    "ecsv.dropna(axis = 0)\n",
    "ecsv = ecsv.head(200)\n",
    "\n",
    "nP = 8\n",
    "rowList = []\n",
    "process = []\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for i in range(nP):\n",
    "    rowList.append(range(i, 2000, nP))\n",
    "print(rowList)\n",
    "if __name__ == '__main__':\n",
    "    queue = [Queue() for i in range(nP)]\n",
    "    process = [Process(target = f, args = (queue[i], ecsv, rowList[i],)) for i in range(nP)]\n",
    "    for p in process:\n",
    "        p.start()\n",
    "    for q in queue:\n",
    "        df = df.append(q.get())\n",
    "    for p in process:\n",
    "        p.join()\n",
    "\n",
    "#print(dList)\n",
    "#print(dList.pop(0))\n",
    "#df = pd.DataFrame(dList, columns=['Id', 'satzID', 'Wort', 'Attribut'])\n",
    "print(df)\n",
    "#df.to_csv('Daten/trainingData.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "c:\\Users\\thilo\\OneDrive\\Dokumente\\Universit채tLeipzig\\DataScience2\\BigData\\tokenizer.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.iloc[b_brand.index.asi8[x]:b_brand.index.asi8[x]+len(bList)]['Attribut'] = \"I-Brand\"\n",
      "     satzId      Wort       Attribut\n",
      "0         0     Front              O\n",
      "1         0  controls              O\n",
      "2         0    Easily  B-Modelnumber\n",
      "3         0   operate              O\n",
      "4         0      your              O\n",
      "..      ...       ...            ...\n",
      "101       0       and              O\n",
      "102       0    remove              O\n",
      "103       0       for              O\n",
      "104       0      easy              O\n",
      "105       0  cleaning              O\n",
      "\n",
      "[106 rows x 3 columns]\n",
      "    satzId   Wort Attribut\n",
      "17       0  Sensi  B-Brand\n",
      "    satzId  Wort Attribut\n",
      "18       0     -  I-Brand\n",
      "19       0  Temp  I-Brand\n",
      "    satzId        Wort Attribut\n",
      "20       0  Technology  E-Brand\n",
      "   satzId    Wort       Attribut\n",
      "2       0  Easily  B-Modelnumber\n",
      "Verarbeitete Produkte: 0\n",
      "c:\\Users\\thilo\\OneDrive\\Dokumente\\Universit채tLeipzig\\DataScience2\\BigData\\tokenizer.py:45: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.iloc[b_brand.index.asi8[x]:b_brand.index.asi8[x]+len(bList)]['Attribut'] = \"I-Brand\"\n",
      "c:\\Users\\thilo\\OneDrive\\Dokumente\\Universit채tLeipzig\\DataScience2\\BigData\\tokenizer.py:68: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.iloc[b_modelnumber.index.asi8[x]:b_modelnumber.index.asi8[x]+len(mList)]['Attribut'] = \"I-Modelnumber\"\n",
      "Verarbeitete Produkte: 1000\n",
      "Verarbeitete Produkte: 2000\n",
      "Verarbeitete Produkte: 3000\n",
      "Verarbeitete Produkte: 4000\n",
      "Verarbeitete Produkte: 5000\n",
      "Verarbeitete Produkte: 6000\n",
      "Verarbeitete Produkte: 7000\n",
      "Verarbeitete Produkte: 8000\n",
      "Verarbeitete Produkte: 9000\n",
      "Verarbeitete Produkte: 10000\n",
      "Verarbeitete Produkte: 11000\n",
      "Verarbeitete Produkte: 12000\n",
      "Verarbeitete Produkte: 13000\n",
      "Verarbeitete Produkte: 14000\n",
      "Verarbeitete Produkte: 15000\n",
      "Verarbeitete Produkte: 16000\n",
      "Verarbeitete Produkte: 17000\n",
      "Verarbeitete Produkte: 18000\n",
      "Verarbeitete Produkte: 19000\n",
      "Verarbeitete Produkte: 20000\n",
      "Verarbeitete Produkte: 21000\n",
      "Verarbeitete Produkte: 22000\n",
      "Verarbeitete Produkte: 23000\n",
      "Verarbeitete Produkte: 24000\n",
      "Verarbeitete Produkte: 25000\n",
      "Verarbeitete Produkte: 26000\n",
      "Verarbeitete Produkte: 27000\n",
      "Verarbeitete Produkte: 28000\n",
      "Verarbeitete Produkte: 29000\n",
      "Verarbeitete Produkte: 30000\n",
      "Verarbeitete Produkte: 31000\n",
      "Verarbeitete Produkte: 32000\n",
      "Verarbeitete Produkte: 33000\n",
      "Verarbeitete Produkte: 34000\n",
      "Verarbeitete Produkte: 35000\n",
      "Verarbeitete Produkte: 36000\n",
      "Verarbeitete Produkte: 37000\n",
      "Verarbeitete Produkte: 38000\n",
      "Verarbeitete Produkte: 39000\n",
      "Verarbeitete Produkte: 40000\n",
      "Verarbeitete Produkte: 41000\n",
      "Verarbeitete Produkte: 42000\n",
      "Verarbeitete Produkte: 43000\n",
      "Verarbeitete Produkte: 44000\n",
      "Verarbeitete Produkte: 45000\n",
      "Verarbeitete Produkte: 46000\n",
      "Verarbeitete Produkte: 47000\n",
      "Verarbeitete Produkte: 48000\n",
      "Verarbeitete Produkte: 49000\n",
      "Verarbeitete Produkte: 50000\n",
      "Verarbeitete Produkte: 51000\n",
      "Verarbeitete Produkte: 52000\n",
      "Verarbeitete Produkte: 53000\n",
      "Verarbeitete Produkte: 54000\n",
      "Verarbeitete Produkte: 55000\n",
      "     satzId      Wort       Attribut\n",
      "0         0     Broan        B-Brand\n",
      "1         0  TEN136WW  B-Modelnumber\n",
      "2         0     Broan        B-Brand\n",
      "3         0  TEN136WW  B-Modelnumber\n",
      "4         0  Overview              O\n",
      "..      ...       ...            ...\n",
      "400   55340       fit              O\n",
      "401   55340        in              O\n",
      "402   55340   tighter              O\n",
      "403   55340    spaces              O\n",
      "404   55340         .              O\n",
      "\n",
      "[12493883 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "import tokenizer as tok\n",
    "\n",
    "ecsv = pd.read_csv('Daten/KoepckeEigen/electronicFixed.csv',escapechar=\"\\\\\",sep=\",\",error_bad_lines=False,warn_bad_lines=False)\n",
    "ecsv.dropna(axis = 0)\n",
    "dList = []\n",
    "df = pd.DataFrame()\n",
    "for index, row in ecsv.iterrows():\n",
    "    df = df.append(tok.tokenizer(index, str(row['name']) + ' ' + str(row['productdescription']), str(row['brand']), str(row['modelnumber'])))\n",
    "    #df = df.append(tokenizer(index, str(row['name']), str(row['brand']), str(row['modelnumber'])))\n",
    "    if index % 1000 == 0:\n",
    "        print('Verarbeitete Produkte:', index)\n",
    "        df.to_csv('Daten/trainingDataInc.csv', index = False)\n",
    "#print(dList)\n",
    "#print(dList.pop(0))\n",
    "#df = pd.DataFrame(dList, columns=['Id', 'satzID', 'Wort', 'Attribut'])\n",
    "print(df)\n",
    "df.to_csv('Daten/trainingData.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "          satzId      Wort       Attribut\n",
      "0              0     Broan        B-Brand\n",
      "1              0  TEN136WW  B-Modelnumber\n",
      "2              0     Broan        B-Brand\n",
      "3              0  TEN136WW  B-Modelnumber\n",
      "4              0  Overview              O\n",
      "...          ...       ...            ...\n",
      "12493878   55340       fit              O\n",
      "12493879   55340        in              O\n",
      "12493880   55340   tighter              O\n",
      "12493881   55340    spaces              O\n",
      "12493882   55340         .              O\n",
      "\n",
      "[12493883 rows x 3 columns]\n",
      "          satzId         Wort       Attribut\n",
      "0              0        Broan        B-Brand\n",
      "1              0     TEN136WW  B-Modelnumber\n",
      "2              0        Broan        B-Brand\n",
      "3              0     TEN136WW  B-Modelnumber\n",
      "4              0     Overview              O\n",
      "...          ...          ...            ...\n",
      "12493473   55339          AND              O\n",
      "12493474   55339  MAINTENANCE              O\n",
      "12493475   55339     Lockable              O\n",
      "12493476   55339      control              O\n",
      "12493477   55339        panel              O\n",
      "\n",
      "[4945017 rows x 3 columns]\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "\"delimiter\" must be string, not int",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-cbd9c9d4581e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'satzId'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mmaxLength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Daten/trainingData'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxLength\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36mto_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, date_format, doublequote, escapechar, decimal, errors)\u001b[0m\n\u001b[0;32m   3168\u001b[0m             \u001b[0mdecimal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdecimal\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3169\u001b[0m         )\n\u001b[1;32m-> 3170\u001b[1;33m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3171\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3172\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\io\\formats\\csvs.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m             \u001b[1;31m# Note: self.encoding is irrelevant here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 196\u001b[1;33m             self.writer = csvlib.writer(\n\u001b[0m\u001b[0;32m    197\u001b[0m                 \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m                 \u001b[0mlineterminator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mline_terminator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: \"delimiter\" must be string, not int"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "maxLength = 300\n",
    "df = pd.read_csv('Daten/trainingdata.csv',escapechar=\"\\\\\",sep=\",\",error_bad_lines=False,warn_bad_lines=False)\n",
    "print(df)\n",
    "df = df.groupby('satzId').filter(lambda x: len(x) <= maxLength)\n",
    "print(df)\n",
    "df.to_csv('Daten/trainingData'+ str(maxLength) + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}