\documentclass[paper=a4,12pt,listof=totoc]{scrartcl}%titlepage,
\usepackage[ngerman]{babel}
\usepackage{amsfonts}
\usepackage[utf8]{inputenx}
\setkomafont{sectioning}{\bfseries} % Serifenschrift auch für Kapitelüberschriften
\usepackage{textcomp} % Symbolsatz
\usepackage{graphicx,setspace,hanging,amsmath,tabularx,acronym} % Grafikeinbindung, Zeilenabstand, Hängender Einzug, Formelsatz, Tabellen, Akronyme, Unterstrich
\usepackage[pdfborder={0 0 0},pdfauthor=Thilo Brummerloh,pdftitle=Bachelorbeit]{hyperref} % Erweiterte PDF Unterstützung (Metadaten, Inhaltsverzeichnis, Verweise, ...)
\usepackage[left=3cm,right=3cm,top=2.5cm,bottom=2.5cm]{geometry}
%\usepackage{natbib}
\usepackage[backend=biber,style=authoryear,citestyle=authoryear-ibid,sorting=nyt]{biblatex} %%%In Editor biber zur Erstellung des Literaturverzeichnisses bestimmen

\addbibresource{Expose.bib}

%opening
\title{Big Data Praktikum: \\ Attribute extraction from eCommerce product descriptions}
\author{Gregor Pfänder 
\and Thilo Brummerloh}

\begin{document}
	\maketitle
	
	\section{Fragen für Freitag}
	\begin{itemize}
		\item Datenvorverarbeitung genau beschreiben?
		\item Machine Learning/Neuronale Netzwerke genauer?
		\item Was wird in Testat gefragt/Ablauf?
		\item Welche Entscheidungen sollen fest stehen?
		\item Weitere Attribute labeln/trainieren? Weitere Schritte wie labeln beschreiben?
	\end{itemize}
	
	\section{Thema}
	Produktseiten von Onlineshops enthalten oft viele unzureichend strukturierte Produktbeschreibungen oder sogar gar keine Beschreibungen. Zum Preisvergleich des gleichen Produkts auf verschiedenen Webseiten muss allerdings bekannt sein um welche Ausprägung eines Produkt es sich handelt. So können Preise nicht nur von Produkten, sondern auch ihren Unterausprägungen, wie dem Speicherplatz oder der Farbe, verglichen werden.
	
	\section{Fragestellung}
	Es sollte möglich sein mithilfe von einem Computerprogramm diese Arbeit automatisch durchzuführen. Wenn Produktspezifikationen innerhalb eines Freitextes vorliegen, sollte es möglich sein daraus Wörter und Wortgruppen zu erkennen und einer Spezifikation zuzuweisen.
	Es soll eine Methode zur Named Entity Recognition ausgewählt werden um Marke und Produktnummer herauszufinden.
	
	\section{Methodenüberblick}
	Alle Methoden lassen sich unter dem Begriff Named Entity Recognition zusammenfassen.	Nachfolgend werden ausgewählte Methoden erklärt. Bei allen handelt es sich um Machine Learning Ansätze. 
	
	\subsection{Naive Bayes}
	Naive Bayes Ansätze waren sehr beliebt\footcite{Ghani.2006}
	Eine Möglichkeit des NER liegt darin das Klassifizierungsproblem mit einem Naive Bayes Klassifikators zu lösen. Bei Naive Bayes wird sich ‚supervised learning‘ zu nutzen gemacht. Es werden also gelabelte Trainingsdaten benötigt. Anhand der Trainingsdaten werden für alle Werte die Wahrscheinlichkeiten bestimmt, dass der Wert einer bestimmten Klasse zugehört (bzw. eine Hypothese erfüllt). In unserem Fall könnten die Werte die Wörter einer Sequenz und mögliche Klassen ‚Attribut‘, ‚Attributwert‘ und ‚Keins von beiden‘ sein. Nachdem die Wahrscheinlichkeiten bekannt sind, können anhand des Naive Bayes Klassifikators die ungelabelten Daten immer der Klasse mit der höchsten Wahrscheinlichkeit zugeordnet werden. Um eine erfolgreiche NER Methode auf Basis von Naive Bayes entwickeln zu können benötigt es noch weitere Schritte wie beispielsweise das Verlinken zwischen Attributen und Attributwerten. 
	Bewertung: Der Naive Bayes Klassifikator ist ein weiteverbreitetes Mittel zur Textklassifizierung und wird beispielsweise bei Spam Filtern erfolgreich eingesetzt um Wörter in die Klassen ‚Spam‘ (Schlecht) oder ‚Ham‘ (gut) einzuordnen. Allerdings ist der Ansatz wie bereits im Namen steht naiv. Er geht davon aus, dass keine Beziehungen zwischen den Werten bestehen. Diese sich also nicht gegenseitig beeinflussen. Diese Annahme ist kritisch bei der Textverarbeitung. In unserem Anwendungsfall könnte sich das unter anderem negativ auf die Extraktion von Attributwerten welche aus mehreren Wörtern zusammengesetzt sind auswirken. Bei solchen Attributwerten bestehen Abhängigkeiten zwischen mehreren Wörtern, die das Modell beachten sollte.
	\footnote{(Quelle: Text Mining for Product Attribute Extraction)
	(Quelle: https://course.elementsofai.com/de/3/3)}
	\subsection{CNNs}
	Neueste Ansätze verwenden CNNs zur Klassifikation. \cite{Zhu.2018} haben erfolgreich ein CNN verwendet um 2017 die genaueste Methode zur Named Entity Recognition von verschiedenen Biologieliteraturkorpora vorzustellen. Die GRAM-CNN genannte Methode hat laut den Autoren für das labeling von Biologieliteratur einen Genauigkeitsvorteil indem, nicht wie in klassischen LSTMs der ganze Satz betrachtet wurde, sondern nur die um ein Wort liegenden Nachbarworte. Die Worte, dieser N-Gram genannten Wortketten, werden in einem ersten Schritt zu einer Darstellung umgewandelt, die nicht das Wort selber enthält, sondern das Wort durch seine einzelnen Buchstaben als Vektor darstellt. Dazu wird dem Wort noch ein Part-of-Speech tag zugewiesen und der Character des Worts als Vektor dargestellt. 
	Die Vektorisierung erfolgt durch Abgleich der Worte mit vorgefertigte Bibliotheken die auf ähnlichen Korpora Vektoren berechnet haben. Das Part-of-Speech tag enthält Informationen zu Abhängigkeiten eines Wortes zu anderen. Eine Eingabe in das GRAM-CNN ist also ein n-gram, das wie beschrieben durch seine Buchstaben mit Zusatzinformationen dargestellt wird.
	Innerhalb des CNNs wird diese Information versteckt verarbeitet und es liefert die features der Worte an ein CRF in dem die Verbindung von mehreren Worten erkannt werden kann. Damit sind auch auseinander geschriebene zusammengehörige Worte als solche erkennbar.\\
	CNNs wurden auch in \cite{Lee.2019} und \cite{Lee.2020} verwendet um Produkteigenschaften aus Benutzerbewertungen zu extrahieren. Mit den extrahierten Eigenschaften werden von den Autoren letztlich Sentiment-Scores der Benutzerbewertungen erstellt, die nicht nur die Erwähnung von bewertbaren Wörtern zählen, sondern auch die relative Gewichtung von verschiedenen Eigenschaften des bewerteten Produkts herausfinden.\\
	\subsection{RNNs (LSTMs)}
	RNNs sind die Standardmethode für Textklassifikation, dabei wird meist die Spezialform der LSTMs verwendet.\footcite{Majumder.30.03.2018}
	RNNs verwenden wie die vorherigen Methoden Trainingsdaten um einen Klassifikator zu trainieren. Eingaben sind Texte aus denen bereits die Interessanten Textstellen mit ihrer Beschreibung extrahiert wurden. Damit wird ein Neuronales Netzwerk trainiert.
	Das trainierte Netzwerk ist dann in der Lage beliebige Texte einzulesen und die darin enthaltenen Entitäten in Form von Markennamen zu erkennen und zuzuordnen. Mit diesen Informationen sollte es möglich sein größere Korpora von Produktbeschreibungen automatisch mit Informationen anzureichern.

	\section{Daten}
	\subsection{Trainingsdaten}
	Je nach Methodenwahl werden unterschiedliche Daten benötigt. Zur Entity Resolution wäre nur ein Menge von ungeordneten Produktbeschreibungen nötig. Wenn allerdings zusätzlich ein Neural Network trainiert werden soll ist es auch nötig einen bereits gelabelten Datensatz zum training zu haben.
	\subsection{title}
	\subsection{Beschreibung Datensatz}
	Zur Verfügung steht ein Datensatz mit 56005 Produkten in Form einer \texttt{.csv}-Datei. Bei den Produkten, die in den Daten erfasst wurden, handelt es sich um unterschiedliche Arten von Haushaltsgeräten. Die Produkte reichen dabei von Waschmaschinen und Wäschetrocknern bis zu Kühlschränken und Mikrowellen. Eine genaue Zusammenfassung welche Produkttypen in den Daten vorkommen, kann durch eine erste Datenbegutachtung nicht getroffen werden. Der Produkttyp wäre also ein weiteres Attribut, bei dem eine Extraktion sinnvoll wäre. Die Werte wurden aus den Produktseiten verschiedener eCommerce Seiten extrahiert. Die Aufteilung der Daten nach Quelle ist wie folgt:\\
	
	\begin{tabular}[h]{|l|r|}
		\hline 
		Quelle & Anzahl \\ \hline 
		shopee.my&24849\\
		appliancesconnection.us&21434\\
		sharafdg.ae&5443\\
		productreview.au&2502\\
		spencerstv.us&1777\\ \hline
	\end{tabular}
	
	Nachdem die .csv Datei mithilfe von Pandas in ein Dataframe überführt wurde, erhält man die Nachfolgende Datenstruktur:\\
	\begin{tabular}[h]{|c|c|c|c|c|c|c|}
		\hline 
		id & source & name & productdescription & url & brand & modelnumber \\ \hline 
	\end{tabular}
		
	Die Zeilen von Interesse sind ‚name‘ und ‚productdescription‘. In diesen Feldern stehen die Sequenzen, aus denen die Attribute extrahiert werden sollen. Außerdem ist der Datensatz bereits für die Attribute ‚brand‘ und ‚modelnumber‘ gelabelt. 
	(der Absatz könnte weggelassen werden. Um einen ersten Eindruck der Daten zu bekommen wird nachfolgen der erste Eintrag des Datensatzes aufgeführt:\\
	\texttt{id: 000266f5e7ab2344315290174dfb75f7 \\
		source: appliancesconnection.us\\
		name: "Broan TEN136WW"\\
		productdecription: "Broan TEN136WW Overview The Tenya 1 Series Under Cabinet Range Hood by Broan offers 2-speed motor with up to 250 CFM of ventilation. [...] Vertical/Horizontal Rectangular Duct 7 in. Vertical Round Duct 1 Year Limited Warranty"\\
		url: https://www.appliancesconnection.com/broan-ten136ww.html?zipcode=20001\\
		brand: Broan\\
		modelnumber: TEN136WW)}
		
	Bei der ersten Begutachtung der Daten sind einige Problemstellen und mögliche Störfaktoren …:\\
		1.	“-Zeichen wird in der Zeile ‚productdescription‘ oft als Größen Bezeichnung benutzt: Dadurch denkt Pandas, dass der Satz vorbei ist und jedes weiter Komma wird als neue Zeile interpretiert…\\
		2.	Chinesiche Zeichen bei mind. einem Produkt\\
		3.	Andere Sonderzeichen: verarbeitbar oder Störfaktoren?\\
		4.	Verschiedene Quellen könnten zu verschiedenen Mustern führen: Beobachten wie gut unser Modell je nach Quelle funktioniert.\\
		5.	Marke und Modelnummer zu einfach zu extrahieren?: weitere Attribute festlegen und von Hand labeln?\\
	
		
	\printbibliography[title=Literaturverzeichnis]
\end{document}
