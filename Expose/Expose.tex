\documentclass[paper=a4,12pt,listof=totoc]{scrartcl}%titlepage,
\usepackage[ngerman]{babel}
\usepackage{amsfonts}
\usepackage[utf8]{inputenx}
\setkomafont{sectioning}{\bfseries} % Serifenschrift auch für Kapitelüberschriften
\usepackage{textcomp} % Symbolsatz
\usepackage{graphicx,setspace,hanging,amsmath,tabularx,acronym} % Grafikeinbindung, Zeilenabstand, Hängender Einzug, Formelsatz, Tabellen, Akronyme, Unterstrich
\usepackage[pdfborder={0 0 0},pdfauthor=Thilo Brummerloh,pdftitle=Bachelorbeit]{hyperref} % Erweiterte PDF Unterstützung (Metadaten, Inhaltsverzeichnis, Verweise, ...)
\usepackage[left=3cm,right=3cm,top=2.5cm,bottom=2.5cm]{geometry}
%\usepackage{natbib}
\usepackage[backend=biber,style=authoryear,citestyle=authoryear-ibid,sorting=nyt]{biblatex} %%%In Editor biber zur Erstellung des Literaturverzeichnisses bestimmen

\addbibresource{Expose.bib}

%opening
\title{Big Data Praktikum: \\ Attribute extraction from eCommerce product descriptions}
\author{Gregor Pfänder 
\and Thilo Brummerloh}

\begin{document}
	\maketitle
	
	\section{Thema}
	Produktseiten von Onlineshops enthalten oft viele unzureichend strukturierte Produktbeschreibungen oder sogar gar keine Beschreibungen. Zum Preisvergleich des gleichen Produkts auf verschiedenen Webseiten muss allerdings bekannt sein um welche Ausprägung eines Produkt es sich handelt. So können Preise nicht nur von Produkten, sondern auch ihren Unterausprägungen, wie dem Speicherplatz oder der Farbe, verglichen werden.
	
	\section{Fragestellung}
	Es sollte möglich sein mithilfe von einem Computerprogramm diese Arbeit automatisch durchzuführen. Sollte ein Produkt auf einer WEbseite keine Produktinformationen haben entsteht ein schwierigeres Problem der Identifikation. Wenn allerdings Produktspezifikationen innerhalb eines Freitextes vorliegen, sollte es möglich sein daraus Wörter und Wortgruppen zu erkennen und einer Spezifikation zuzuweisen.
	Es soll eine Methode zur Named Entity Recognition ausgewählt werden.
	
	
	\section{Methoden}
	\subsection{Auswahl der Methode}
	Alle Methoden lassen sich unter dem Begriff Named Entity Recognition zusammenfassen. Um das Problem zu lösen werden Machine Learning Methoden verwendet. Diese können in Überwachte und unüberwachte Ansätz gegliedert werden.
	
	Überwachte Ansätze basieren meist auf CRF und HMM
	
	\subsubsection{Naive Bayes}
	Naive Bayes Ansätze waren sehr beliebt\footcite{Ghani.2006}
	Eine Möglichkeit des NER liegt darin das Klassifizierungsproblem mit einem Naive Bayes Klassifikators zu lösen. Bei Naive Bayes wird sich ‚supervised learning‘ zu nutzen gemacht. Es werden also gelabelte Trainingsdaten benötigt. Anhand der Trainingsdaten werden für alle Werte die Wahrscheinlichkeiten bestimmt, dass der Wert einer bestimmten Klasse zugehört (bzw. eine Hypothese erfüllt). In unserem Fall könnten die Werte die Wörter einer Sequenz und mögliche Klassen ‚Attribut‘, ‚Attributwert‘ und ‚Keins von beiden‘ sein. Nachdem die Wahrscheinlichkeiten bekannt sind, können anhand des Naive Bayes Klassifikators die ungelabelten Daten immer der Klasse mit der höchsten Wahrscheinlichkeit zugeordnet werden. Um eine erfolgreiche NER Methode auf Basis von Naive Bayes entwickeln zu können benötigt es noch weitere Schritte wie beispielsweise das Verlinken zwischen Attributen und Attributwerten. 
	Bewertung: Der Naive Bayes Klassifikator ist ein weiteverbreitetes Mittel zur Textklassifizierung und wird beispielsweise bei Spam Filtern erfolgreich eingesetzt um Wörter in die Klassen ‚Spam‘ (Schlecht) oder ‚Ham‘ (gut) einzuordnen. Allerdings ist der Ansatz wie bereits im Namen steht naiv. Er geht davon aus, dass keine Beziehungen zwischen den Werten bestehen. Diese sich also nicht gegenseitig beeinflussen. Diese Annahme ist kritisch bei der Textverarbeitung. In unserem Anwendungsfall könnte sich das unter anderem negativ auf die Extraktion von Attributwerten welche aus mehreren Wörtern zusammengesetzt sind auswirken. Bei solchen Attributwerten bestehen Abhängigkeiten zwischen mehreren Wörtern, die das Modell beachten sollte.
	\footnote{(Quelle: Text Mining for Product Attribute Extraction)
	(Quelle: https://course.elementsofai.com/de/3/3)}
	\subsubsection{CNNs}
	Neueste Ansätze verwenden CNNs zur Klassifikation. \cite{Zhu.2018} haben erfolgreich ein CNN verwendet um 2017 die genaueste Methode zur Named Entity Recognition von verschiedenen Biologieliteraturkorpora vorzustellen. Die GRAM-CNN genannte Methode hat laut den Autoren für das labeling von Biologieliteratur einen Genauigkeitsvorteil indem, nicht wie in klassischen LSTMs der ganze Satz betrachtet wurde, sondern nur die um ein Wort liegenden Nachbarworte. Die Worte, dieser N-Gram genannten Wortketten, werden in einem ersten Schritt zu einer Darstellung umgewandelt, die nicht das Wort selber enthält, sondern das Wort durch seine einzelnen Buchstaben als Vektor darstellt. Dazu wird dem Wort noch ein Part-of-Speech tag zugewiesen und der Character des Worts als Vektor dargestellt. 
	Die Vektorisierung erfolgt durch Abgleich der Worte mit vorgefertigte Bibliotheken die auf ähnlichen Korpora Vektoren berechnet haben. Das Part-of-Speech tag enthält Informationen zu Abhängigkeiten eines Wortes zu anderen. Eine Eingabe in das GRAM-CNN ist also ein n-gram, das wie beschrieben durch seine Buchstaben mit Zusatzinformationen dargestellt wird.
	Innerhalb des CNNs wird diese Information versteckt verarbeitet und es liefert die features der Worte an ein CRF in dem die Verbindung von mehreren Worten erkannt werden kann. Damit sind auch auseinander geschriebene zusammengehörige Worte als solche erkennbar.\\
	CNNs wurden auch in \cite{Lee.2019} und \cite{Lee.2020} verwendet um Produkteigenschaften aus Benutzerbewertungen zu extrahieren. Mit den extrahierten Eigenschaften werden von den Autoren letztlich Sentiment-Scores der Benutzerbewertungen erstellt, die nicht nur die Erwähnung von bewertbaren Wörtern zählen, sondern auch die relative Gewichtung von verschiedenen Eigenschaften des bewerteten Produkts herausfinden.\\
	\subsubsection{RNNs (LSTMs)}
	RNNs sind die Standardmethode für Textklassifikation, dabei wird meist die Spezialform der LSTMs verwendet.\footcite{Majumder.30.03.2018}
	RNNs verwenden wie die vorherigen Methoden Trainingsdaten um einen Klassifikator zu trainieren. Eingaben sind Texte aus denen bereits die Interessanten Textstellen mit ihrer Beschreibung extrahiert wurden. Damit wird ein Neuronales Netzwerk trainiert.
	Das trainierte Netzwerk ist dann in der Lage beliebige Texte einzulesen und die darin enthaltenen Entitäten in Form von Markennamen zu erkennen und zuzuordnen. Mit diesen Informationen sollte es möglich sein größere Korpora von Produktbeschreibungen automatisch mit Informationen anzureichern.
	
	\subsubsection{Andere Überlegungen}
	Supervised Learning, semi-supervised Learning\footcite{Ghani.2006}, oder Unsupervised Learning? Semi, oder Unsupervised Learning
	
	Klassische RNNs oder LSTMs? LSTM optimalerweise\footcite{Majumder.30.03.2018}{S. 3} Majumder beschreibt verschieden tiefe LSTMs, 
	\subsection{Trainieren des Modells}
	
	\section{Daten}
	\subsection{Trainingsdaten}
	Je nach Methodenwahl werden unterschiedliche Daten benötigt. Zur Entity Resolution wäre nur ein Menge von ungeordneten Produktbeschreibungen nötig. Wenn allerdings zusätzlich ein Neural Network trainiert werden soll ist es auch nötig einen bereits gelabelten Datensatz zum training zu haben.
	\subsection{Zu klassifizierende Daten}
	\subsection{Beschreibung Datensatz}
		Zur Verfügung steht ein Datensatz mit 56005 Produkten in Form einer .csv Datei. Bei den Produkten, die in den Daten erfasst wurden, handelt es sich um unterschiedliche Arten von Haushaltsgeräten. Die Produkte reichen dabei von Waschmaschinen und Wäschetrocknern bis zu Kühlschränken und Mikrowellen. Eine genaue Zusammenfassung welche Produkttypen genau in den Daten vorkommen kann durch eine erste Datenbegutachtung nicht getroffen werden. Der Produkttyp wäre also ein weiteres Attribut, bei dem eine Extraktion sinnvoll wäre.
		Die Werte wurden aus den Produktseiten verschiedener eCommerce Seiten extrahiert. Die Aufteilung der Daten nach Quelle ist wie folgt:
		Quelle	Anzahl
		shopee.my	24849
		appliancesconnection.us	21434
		sharafdg.ae	5443
		productreview.au	2502
		spencerstv.us	1777
		
		Nachdem die .csv Datei mithilfe von Pandas in ein Dataframe überführt wurde, erhält man die Nachfolgende Datenstruktur:
		id	source	name 	productdescription	url	brand	modelnumber
		…	…	…	…	…	…	…
		…	…	…	…	…	…	…
		…	…	…	…	…	…	…
		
		Die Zeilen von Interesse sind ‚name‘ und ‚productdescription‘. In diesen Feldern stehen die Sequenzen, aus denen die Attribute extrahiert werden sollen. Außerdem ist der Datensatz bereits für die Attribute ‚brand‘ und ‚modelnumber‘ gelabelt. 
		(der Absatz könnte weggelassen werden. Um einen ersten Eindruck der Daten zu bekommen wird nachfolgen der erste Eintrag des Datensatzes aufgeführt:
		id: 000266f5e7ab2344315290174dfb75f7
		source: appliancesconnection.us
		name: "Broan TEN136WW"
		productdecription: "Broan TEN136WW Overview The Tenya 1 Series Under Cabinet Range Hood by Broan offers 2-speed motor with up to 250 CFM of ventilation. The hood also features the Captur™ System, rocker switches and a mesh filter. Available at AppliancesConnection Features: Captur™ System The Captur™ system’s advanced blower design features a forward positioned centric inlet to remove smoke and odor faster. Two-speed blower control exhausts at 250 CFM Max high Quiet Operation Smooth-flow blower wheel design and high flow filters ensure quiet, 1.5 sones operation at normal speed Halogen Lighting Two-level, halogen bulbs flood the cooktop and surrounding area with generous illumination. (50W bulbs sold separately.) Rocker Switches Hidden on/off rocker switches controls two blower speeds and light levels Mesh Filter Large dishwasher-safe, single open mesh filter provides efficient grease removal Additional Features: ADA capable (Kit Sold Separately) Non-duct capable (Filter Sold Separately) 3¼ in. x 10 in. Vertical/Horizontal Rectangular Duct 7 in. Vertical Round Duct 1 Year Limited Warranty"
		url: https://www.appliancesconnection.com/broan-ten136ww.html?zipcode=20001
		brand: Broan
		modelnumber: TEN136WW)
		
		Bei der ersten Begutachtung der Daten sind einige Problemstellen und mögliche Störfaktoren …:
		1.	“-Zeichen wird in der Zeile ‚productdescription‘ oft als Größen Bezeichnung benutzt  Dadurch denkt Pandas, dass der Satz vorbei ist und jedes weiter Komma wird als neue Zeile interpretiert…
		2.	Chinesiche Ziechen bei mind. einem Produkt
		3.	Andere Sonderzeichen  verarbeitbar oder Störfaktoren?
		4.	Verschiedene Quellen könnten zu verschiedenen Mustern führen  Beobachten wie gut unser Modell je nach Quelle funktioniert.
		5.	Marke und Modelnummer zu einfach zu extrahieren?  weitere Attribute festlegen und von Hand labeln?
		
		
	\printbibliography[title=Literaturverzeichnis]
\end{document}
